<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<title>Machine Learning 영한 사전 - For Data Analytics</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Machine Learning 영한 사전" />
<meta property="og:description" content="기계학습(Machine Learning) 영문 단어를 한글로 번역하기 위한 간단한 사전입니다.
Accuracy : 정확도
Activation function : 활성화 함수
ADAptive GRADient descent(AdaGrad) : 적응형 경사하강법
ADAptive Moment estimation(Adam) : 적응형 모멘트 추정
Affine transformation : 어파인 변환
Algorithm : 알고리즘
Anomaly Detection : 이상 탐지
API Dataset API : 데이터셋
API Layers API : 계층
API Metrics API : 메트릭" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://manboha.github.io/post/2021-09-20-machine-learning-dictionary/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-09-20T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-09-20T00:00:00+00:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="For Data Analytics" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">For Data Analytics</div>
					<div class="logo__tagline">Beyond the gate of experience flows the Way</div>
				</div>
		</a>
	</div>
		
<nav class="menu">
	<button class="menu__btn" aria-haspopup="true" aria-expanded="false" tabindex="0">
		<span class="menu__btn-title" tabindex="-1">Menu</span>
	</button>
	<ul class="menu__list">
		<li class="menu__item">
			<a class="menu__link" href="/">
				
				<span class="menu__text">Home</span>
				
			</a>
		</li>
		<li class="menu__item">
			<a class="menu__link" href="/about/">
				
				<span class="menu__text">About</span>
				
			</a>
		</li>
	</ul>
</nav>

	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Machine Learning 영한 사전</h1>
			<div class="post__meta meta">
<div class="meta__item-datetime meta__item">
	<svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0C7 0 1 6 1 14s6 14 14 14 14-6 14-14S23 0 15 0zm0 25C9 25 4 20 4 14S9 3 15 3s11 5 11 11-5 11-11 11zm1-18h-2v8.4l6.8 4.4L22 18l-6-3.8V7z"/></svg><time class="meta__text" datetime="2021-09-20T00:00:00Z">September 20, 2021</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2l1 2h8v11h-16v-13z"/></svg><span class="meta__text"><a class="meta__link" href="/categories/machine-learning/" rel="category">Machine Learning</a>
	</span>
</div></div>
		</header>
		<div class="content post__content clearfix">
			
<script src="https://manboha.github.io/post/2021-09-20-machine-learning-dictionary/index_files/header-attrs/header-attrs.js"></script>


<p><code>기계학습(Machine Learning)</code> 영문 단어를 한글로 번역하기 위한 간단한 사전입니다.</p>
<ul>
<li><p>Accuracy : 정확도</p></li>
<li><p>Activation function : 활성화 함수</p></li>
<li><p>ADAptive GRADient descent(AdaGrad) : 적응형 경사하강법</p></li>
<li><p>ADAptive Moment estimation(Adam) : 적응형 모멘트 추정</p></li>
<li><p>Affine transformation : 어파인 변환</p></li>
<li><p>Algorithm : 알고리즘</p></li>
<li><p>Anomaly Detection : 이상 탐지</p></li>
<li><p>API Dataset API : 데이터셋</p></li>
<li><p>API Layers API : 계층</p></li>
<li><p>API Metrics API : 메트릭</p></li>
<li><p>Area under the curve(AUC) : 곡선 아래 면적</p></li>
<li><p>Artificial Neural Network : 인공신경망</p></li>
<li><p>Association Rule Learning : 연관 규칙 학습</p></li>
<li><p>Autoencoder : 오토인코더</p></li>
<li><p>Average pooling : 평균 풀링<br />
</p></li>
<li><p>Backpropagation : 오차역전파법</p></li>
<li><p>Backpropagation Through Time : 시간 기반 오차역전파법</p></li>
<li><p>Backward propagation : 역전파</p></li>
<li><p>Baseline : 기준선</p></li>
<li><p>Batch : 배치 (모델 업데이트 샘플 묶음 수)</p></li>
<li><p>Batch Learning : 배치 학습</p></li>
<li><p>Batch Nomalization : 배치 정규화</p></li>
<li><p>Batch size : 배치 크기</p></li>
<li><p>Bayesian : 베이지언</p></li>
<li><p>Bias : 편향</p></li>
<li><p>Bidirected RNN : 양방향 순환 신경망</p></li>
<li><p>Bilinear interpolation : 이중선형 보간</p></li>
<li><p>Binary classification : 이진 분류</p></li>
<li><p>Binomial Distribution : 이항분포</p></li>
<li><p>Binomial Logistic Regression : 이항 로지스틱 회귀</p></li>
<li><p>Bucketing : 버킷팅</p></li>
<li><p>Calibration layer : 교정층</p></li>
<li><p>Candidate sampling : 후보 샘플링</p></li>
<li><p>Categorical data : 범주형 데이터</p></li>
<li><p>Category : 범주</p></li>
<li><p>Central Limit Theorem : 중심 극한의 원리</p></li>
<li><p>Centroid : 중심(센트로이드)</p></li>
<li><p>Chain rule : 연쇄법칙</p></li>
<li><p>Checkpoint : 체크포인트</p></li>
<li><p>Chi-sqare : 카이제곱</p></li>
<li><p>Chi-sqare Feature Selection : 카이제곱 특성 선택법</p></li>
<li><p>Class : 범주</p></li>
<li><p>Classification : 분류</p></li>
<li><p>classification model : 분류 모델</p></li>
<li><p>Classification threshold : 분류 임계값</p></li>
<li><p>Class-imbalanced data set : 범주 불균형 데이터셋</p></li>
<li><p>Closed-form Solution : 닫힌 형태의 해</p></li>
<li><p>Clustering : 군집</p></li>
<li><p>CNN : 합성곱 신경망</p></li>
<li><p>Coefficient : 계수</p></li>
<li><p>Collaborative filtering : 협업 필터링</p></li>
<li><p>Computational Complexity : 계산 복잡도</p></li>
<li><p>Confidence Interval : 신뢰구간</p></li>
<li><p>Confidence Level : 신뢰수준</p></li>
<li><p>Confuse Matrix : 혼동 행렬</p></li>
<li><p>Confusion matrix : 혼동 행렬</p></li>
<li><p>Continuous feature : 연속 특성</p></li>
<li><p>Continuous Probability Distribution : 연속 확률 분포</p></li>
<li><p>Continuous Random Variable : 연속 확률 변수</p></li>
<li><p>Convergence : 수렴</p></li>
<li><p>Convex : 볼록</p></li>
<li><p>Convex function : 볼록 함수</p></li>
<li><p>Convex optimization : 볼록 최적화</p></li>
<li><p>Convex set : 볼록 집합</p></li>
<li><p>Convolution : 합성곱</p></li>
<li><p>Convolutional filter : 합성곱 필터</p></li>
<li><p>Convolutional layer : 합성곱층</p></li>
<li><p>Convolutional neural network : 합성곱 신경망</p></li>
<li><p>Convolutional operation : 합성곱 연산</p></li>
<li><p>Corpus : 말뭉치</p></li>
<li><p>Correlation Coefficient : 상관 계수</p></li>
<li><p>Cosine Similarity : 코사인 유사도</p></li>
<li><p>Cost : 비용</p></li>
<li><p>Cost Function : 비용 함수</p></li>
<li><p>Cross Entropy : 교차 엔트로피</p></li>
<li><p>Cross Validation : 교차 검증</p></li>
<li><p>Cross Validation Error : 교차 검증 오차</p></li>
<li><p>Cross-entropy : 크로스엔트로피</p></li>
<li><p>Cumulative Reward : 누적 보상</p></li>
<li><p>Curse of Dimensionality : 차원의 저주</p></li>
<li><p>Data analysis : 데이터 분석</p></li>
<li><p>Data augmentation : 데이터 증식</p></li>
<li><p>Data Mining : 데이터 마아닝</p></li>
<li><p>Data set : 데이터셋</p></li>
<li><p>Data Snooping Bias : 데이터 스누핑 편향</p></li>
<li><p>DataFrame : 데이터프레임</p></li>
<li><p>Dataset : 데이터셋</p></li>
<li><p>Decision boundary : 결정 경계</p></li>
<li><p>Decision Function : 결정 함수</p></li>
<li><p>Decision Tree : 결정 트리</p></li>
<li><p>Deep Belief Network : 심층 신뢰 신경망</p></li>
<li><p>Deep learning : 딥러닝</p></li>
<li><p>Deep Model : 심층 모델</p></li>
<li><p>Deep Neural Network(DNN) : 심층 신경망</p></li>
<li><p>Deep Reinforcement Learning : 심층 강화 학습ㅊ</p></li>
<li><p>Default Value : 기본값</p></li>
<li><p>Degree of Freedom : 자유도</p></li>
<li><p>Dense feature : 밀집 특성</p></li>
<li><p>Dense layer : 밀집 층</p></li>
<li><p>Density Estimation : 밀도 추정</p></li>
<li><p>Density-based clustering : 밀도 기반 클러스터링</p></li>
<li><p>Dependent Variable : 종속 변수</p></li>
<li><p>Derived feature : 파생 특성</p></li>
<li><p>Deviation : 편차</p></li>
<li><p>Device : 디바이스</p></li>
<li><p>Diagram : 그림, 도식, 도표</p></li>
<li><p>Dimensionality Reduction : 차원 축소</p></li>
<li><p>Discrete feature : 불연속 특성</p></li>
<li><p>Discrete Probability Distribution : 이산 확률 분포</p></li>
<li><p>Discrete Random Variable : 이산 확률 변수</p></li>
<li><p>Document Categorization : 문서 분류</p></li>
<li><p>Document Classification : 문서 분류</p></li>
<li><p>Document Frequency : 문서 빈도</p></li>
<li><p>Document Segmentation : 문서 세그멘테이션</p></li>
<li><p>Dot product : 스칼라 곱</p></li>
<li><p>Double Precision : 배정밀도</p></li>
<li><p>Dropout : 드롭아웃</p></li>
<li><p>Dropout regularization : 탈락 정규화</p></li>
<li><p>Dynamic model : 동적 모델</p></li>
<li><p>Early stopping : 조기 중단</p></li>
<li><p>Edge : 윤곽선</p></li>
<li><p>Edit Distance : 편집 거리</p></li>
<li><p>Element : 요소, 개체, 레코드</p></li>
<li><p>Embedding Learning : 임베딩 학습</p></li>
<li><p>Embedding : 임베딩</p></li>
<li><p>Empirical risk minimization : 경험적 위험 최소화</p></li>
<li><p>Ensemble : 앙상블</p></li>
<li><p>Ensemble learning : 앙상블 학습</p></li>
<li><p>Ensemble method : 앙상블 방법</p></li>
<li><p>Epoch : 에포크 (학습 횟수)</p></li>
<li><p>Error : 오차</p></li>
<li><p>Error Function : 오차 함수</p></li>
<li><p>Error Rate : 오차율</p></li>
<li><p>Estimate : 추정값 (추정 결과)</p></li>
<li><p>Estimation : 추정 (추정 절차)</p></li>
<li><p>Estimator : 추정량 (추정 함수)</p></li>
<li><p>Example : 사례</p></li>
<li><p>Expectation Maximization : 기댓값 최대화</p></li>
<li><p>Expected Value : 기대값</p></li>
<li><p>Expert System : 전문가 시스템</p></li>
<li><p>Exponential function : 지수 함수</p></li>
<li><p>Factor Matrix : 요인 행렬</p></li>
<li><p>False Negative : 거짓 음성</p></li>
<li><p>False Positive : 거짓 양성</p></li>
<li><p>False positive rate : 거짓 양성률</p></li>
<li><p>Feature : 특성</p></li>
<li><p>Feature column : 특성 열</p></li>
<li><p>Feature cross : 특성 조합</p></li>
<li><p>Feature Engineering : 특성 공학</p></li>
<li><p>Feature Extraction : 특성 추출</p></li>
<li><p>Feature Importance : 특성 중요도</p></li>
<li><p>Feature map : 특성 맵</p></li>
<li><p>Feature Selection : 특성 선정</p></li>
<li><p>Feature set : 특성 집합</p></li>
<li><p>Feature spec : 특성 명세</p></li>
<li><p>Few-shot learning : 퓨-샷-러닝</p></li>
<li><p>Filter : 필터</p></li>
<li><p>Forget gate : 망각 게이트</p></li>
<li><p>Full softmax : 풀 소프트맥스</p></li>
<li><p>Fully connected layer : 완전 연결층</p></li>
<li><p>Gaussian Mixture Model : 가우시안 혼합 모형</p></li>
<li><p>Generalization : 일반화</p></li>
<li><p>Generalization Error : 일반화 오차</p></li>
<li><p>Generalization linear model : 일반화 선형 모델</p></li>
<li><p>Global Minimum : 전역 최솟값</p></li>
<li><p>Gradient : 기울기</p></li>
<li><p>Gradient Ascent Method : 경사 상승법</p></li>
<li><p>Gradient clipping : 기울기 다듬기</p></li>
<li><p>Gradient descent : 기울기 하강</p></li>
<li><p>Gradient Descent Method : 경사 하강법</p></li>
<li><p>Gradient Method : 경사법</p></li>
<li><p>Gradient Vanishing : 기울기 소실</p></li>
<li><p>Graph : 그래프</p></li>
<li><p>Heuristic : 휴리스틱</p></li>
<li><p>Hidden layer : 은닉층</p></li>
<li><p>Hierarchical Clustering Analysis : 계층 군집 분석</p></li>
<li><p>Hinge loss : 경첩 손실</p></li>
<li><p>Hold-out : 홀드아웃</p></li>
<li><p>holdout data : 예비 데이터</p></li>
<li><p>Hyperparameter : 하이퍼 파라미터</p></li>
<li><p>Hyperplane : 초평면</p></li>
<li><p>Hypothesis : 가설</p></li>
<li><p>Identify function : 항등 함수</p></li>
<li><p>Image Classification : 이미지 분류</p></li>
<li><p>Image Detection : 이미지 검출</p></li>
<li><p>Imbalanced Dataset : 불균형 데이터셋</p></li>
<li><p>Incremental Learning : 점진적 학습</p></li>
<li><p>Independently and identically distributed : 독립적이고 동일한 분포</p></li>
<li><p>Inference : 추론</p></li>
<li><p>Input function : 입력 함수</p></li>
<li><p>Input Gate : 입력 게이트</p></li>
<li><p>Input layer : 입력층</p></li>
<li><p>Instance : 사례</p></li>
<li><p>Instanced-based Learning : 사례 기반 학습</p></li>
<li><p>Interpretability : 해석력</p></li>
<li><p>Inter-rater agreement : 평가자간 합의</p></li>
<li><p>Iteration : 반복</p></li>
<li><p>Jaccard Coefficient : 자카드 계수</p></li>
<li><p>Kernel : 커널</p></li>
<li><p>Kernel Support Vector Machines : 커널 서포트 벡터 머신</p></li>
<li><p>K-fold cross-validation : K겹 교차검증</p></li>
<li><p>K-Means : K-평균</p></li>
<li><p>K-Nearest Neighbors : K-최근접 이웃</p></li>
<li><p>Knowledge Discovery : 지식발견</p></li>
<li><p>Label : 레이블</p></li>
<li><p>Labeled example : 레이블된 보기</p></li>
<li><p>Labeling : 라벨링, 식별화</p></li>
<li><p>Lambda : 람다</p></li>
<li><p>Lasso Regression : 라쏘 회귀</p></li>
<li><p>Latent Factor Model : 잠재 요소 모델</p></li>
<li><p>Latent Variable : 잠재변수</p></li>
<li><p>Layer : 계층</p></li>
<li><p>Learning : 학습</p></li>
<li><p>Learning Rate : 학습률</p></li>
<li><p>Learning Rate Decay : 학습률 감소</p></li>
<li><p>Learning Schedule : 학습 스케줄</p></li>
<li><p>Least square method : 최소 자승법 (최소 제곱법)</p></li>
<li><p>Least squares regression : 최소 제곱 회귀</p></li>
<li><p>Likelihood : 가능도</p></li>
<li><p>Linear regression : 선형회귀</p></li>
<li><p>Local Minimum : 지역 최솟값</p></li>
<li><p>Locality Linear Embedding : 지역 선형 임베딩</p></li>
<li><p>Log Loss : 로그 손실</p></li>
<li><p>Logistic Regression : 로지스틱 회귀</p></li>
<li><p>Loss : 손실</p></li>
<li><p>Loss function : 손실 함수</p></li>
<li><p>Machine learning : 기계 학습</p></li>
<li><p>MAD(Mean Absolute Derivation) : 평균 절대 편차</p></li>
<li><p>MAE(Mean Absolute Error) : 평균 절대 오차</p></li>
<li><p>Manifold Learning : 매니폴드 학습</p></li>
<li><p>MAPE(Mean Absolute Percentage Error) : 평균 절대 백분비 오차</p></li>
<li><p>Margin : 간격</p></li>
<li><p>Margin Violation : 마진 오류</p></li>
<li><p>Matrix Decomposition : 행렬 분해</p></li>
<li><p>Matrix Factorization : 행렬 분해</p></li>
<li><p>Maximum likelihood method : 최대 가능도 방법</p></li>
<li><p>Mean Absolute Error : 평균 절대 오차</p></li>
<li><p>Mean Squared Error : 평균 제곱 오차</p></li>
<li><p>Metric : 메트릭 (척도, 평가지표)</p></li>
<li><p>Mini-batch : 작은 배치</p></li>
<li><p>Mini-batch stochastic gradient descent : 작은 배치 확률적 기울기 하강</p></li>
<li><p>Mixture normal distribution : 혼합 정규분포</p></li>
<li><p>Missing Value : 결측값</p></li>
<li><p>Model : 모델</p></li>
<li><p>Model function : 모델 함수</p></li>
<li><p>Model Parallelism : 모델 병렬화</p></li>
<li><p>Model training : 모델 훈련</p></li>
<li><p>Model-based Learning : 모델 기반 학습</p></li>
<li><p>Momentum : 모멘텀</p></li>
<li><p>MSE(Mean Square Error) : 평균 제곱 오차</p></li>
<li><p>Multi-class classification : 다중범주 분류</p></li>
<li><p>Multi-layer Perceptron : 다층 퍼셉트론</p></li>
<li><p>Multinomial classification : 다항 분류</p></li>
<li><p>Multinomial Logistic Regression : 다항 로지스틱 회귀</p></li>
<li><p>Multivariate regression : 다변량 회귀</p></li>
<li><p>Naive Bayes Classifier : 나이브 베이즈 분류기</p></li>
<li><p>Named Entity Resolution : 고유명사 추출</p></li>
<li><p>Native log-likelihood : 음의 로그 가능도</p></li>
<li><p>Negative class : 음성 범주</p></li>
<li><p>Neural Language Processing : 자연어 처리</p></li>
<li><p>Neural network : 신경망</p></li>
<li><p>Neuron : 뉴런</p></li>
<li><p>Node : 노드</p></li>
<li><p>Noise : 노이즈</p></li>
<li><p>Nonresponse Bias : 비응답 편향</p></li>
<li><p>Normalization : 정규화</p></li>
<li><p>Numerical data : 수치 데이터</p></li>
<li><p>Numerical differentiation : 수치 미분</p></li>
<li><p>Object Recognition : 사물 인식</p></li>
<li><p>Objective : 목적</p></li>
<li><p>Objective Function : 목적함수</p></li>
<li><p>Observed variable : 관측변수</p></li>
<li><p>OCR(Optical Character Recognition) : 광학 문자 판독기</p></li>
<li><p>Offline inference : 오프라인 추론</p></li>
<li><p>Offline Learning : 오프라인 학습</p></li>
<li><p>One-hot encoding : 원-핫 인코딩</p></li>
<li><p>One-shot learning : 원-샷-러닝</p></li>
<li><p>One-vs.-all : 일-대-다</p></li>
<li><p>Online inference : 온라인 추론</p></li>
<li><p>Online Learning : 온라인 학습</p></li>
<li><p>Operation : 연산</p></li>
<li><p>Optimal Policy : 최적 정책</p></li>
<li><p>Optimization : 최적화</p></li>
<li><p>Optimizer : 최적화기</p></li>
<li><p>Outlier : 이상치</p></li>
<li><p>Out-of-Sample Error : 외부 샘플 오류</p></li>
<li><p>Output layer : 출력층</p></li>
<li><p>Overfitting : 과적합</p></li>
<li><p>Padding : 패딩</p></li>
<li><p>Parameter : 파라미터</p></li>
<li><p>Parameter update : 파라미터 업데이트</p></li>
<li><p>Partial derivative : 편도함수</p></li>
<li><p>Partitioning strategy : 구획 전략</p></li>
<li><p>Penalty : 벌점</p></li>
<li><p>Pencentile : 백분위수</p></li>
<li><p>Perceptron : 퍼셉트론</p></li>
<li><p>Perceptron convergence theorem : 퍼셉트론 수렴 정리</p></li>
<li><p>Performance : 성능</p></li>
<li><p>Perplexity : 혼잡도</p></li>
<li><p>Pipeline : 파이프라인</p></li>
<li><p>Policy : 정책</p></li>
<li><p>Polynomial Regression : 다항식 회귀</p></li>
<li><p>Pooling : 풀링</p></li>
<li><p>Pooling Layer : 풀링 레이어</p></li>
<li><p>Population : 모집단</p></li>
<li><p>POS Tagging : 품사 테깅</p></li>
<li><p>Positive class : 양성 범주</p></li>
<li><p>Precision : 정밀도</p></li>
<li><p>Prediction : 예측</p></li>
<li><p>Prediction bias : 예측 편향</p></li>
<li><p>Predictor Variable : 예측 변수</p></li>
<li><p>Pre-trained model : 사전 학습된 모델</p></li>
<li><p>Pre-training : 선행 학습</p></li>
<li><p>Principal Component Analysis(PCA) : 주성분 분석</p></li>
<li><p>Prior belief : 사전 믿음</p></li>
<li><p>Probability : 확률</p></li>
<li><p>Problem Statement : 문제 진술</p></li>
<li><p>Projection : 투영</p></li>
<li><p>Q-Learning : 큐-러닝</p></li>
<li><p>Quartile : 사분위수</p></li>
<li><p>Queue : 큐</p></li>
<li><p>Random Forest : 랜덤 포레스트</p></li>
<li><p>Random Initialization : 무작위 초기화</p></li>
<li><p>Random Variable : 확률변수</p></li>
<li><p>Rank : 랭크</p></li>
<li><p>Rater : 평가자</p></li>
<li><p>Real-Time Recurrent Learning : 실시간 순환 학습</p></li>
<li><p>Recall : 재현율</p></li>
<li><p>Receiver Operating Characteristic(ROC) : 수신기 조작 특성</p></li>
<li><p>Recurrent Neural Network(RNN) : 순환 신경망</p></li>
<li><p>Regression : 회귀</p></li>
<li><p>Regression model : 회귀 모델</p></li>
<li><p>Regression Performance Metrics : 회귀 성능 평가 지표</p></li>
<li><p>Regularization : 정규화</p></li>
<li><p>Regularization rate : 정규화율</p></li>
<li><p>Reinforcement Learning : 강화 학습</p></li>
<li><p>ReLU function : ReLU 함수</p></li>
<li><p>Representation : 표현</p></li>
<li><p>Representation Learning : 표현 학습</p></li>
<li><p>Residual error : 잔여 오차</p></li>
<li><p>Residuals : 잔차</p></li>
<li><p>Restricted Boltzmann Machine : 제한된 볼츠만 머신</p></li>
<li><p>Reward : 보상</p></li>
<li><p>Robo Advisor : 로보 어드바이저</p></li>
<li><p>Root directory : 루트 디렉토리</p></li>
<li><p>Root Mean Square Error(RSME) : 평균 제곱근 오차</p></li>
<li><p>Rotational invariance : 회전 불변성</p></li>
<li><p>Rounding Error : 반올림 오차</p></li>
<li><p>Saddle point : 안정점</p></li>
<li><p>Sample : 사례, 표본</p></li>
<li><p>Sample Space : 표본 공간</p></li>
<li><p>Sampling Noise : 샘플링 잡음</p></li>
<li><p>Sampling Bias : 샘플링 편향</p></li>
<li><p>Scaling : 범위 조절</p></li>
<li><p>Scatter plot : 산포도, 산점도</p></li>
<li><p>Self-Organization : 자기 조직화</p></li>
<li><p>Semi-supervised Learning : 준지도 학습</p></li>
<li><p>Sequence model : 시퀀스 모델</p></li>
<li><p>Session : 세션</p></li>
<li><p>Shape : 형상</p></li>
<li><p>Sigmoid function : 시그모이드 함수</p></li>
<li><p>Signal : 시그널</p></li>
<li><p>Simularity : 유사도</p></li>
<li><p>Singular Value Decomposition : 특잇값 분해</p></li>
<li><p>Singularity : 특이점</p></li>
<li><p>Size invariance : 크기 불변성</p></li>
<li><p>Softmax : 소프트맥스</p></li>
<li><p>Sparse feature : 희박한 특성</p></li>
<li><p>Sparse representation : 희박한 표현</p></li>
<li><p>Sparsity : 희박성</p></li>
<li><p>Spatial pooling : 공간적 풀링</p></li>
<li><p>Speech Recognition : 음성 인식</p></li>
<li><p>Squared euclidean distance : 제곱 유클리드 거리</p></li>
<li><p>Squared hinge loss : 제곱 경첩 손실</p></li>
<li><p>Squared loss : 제곱 손실</p></li>
<li><p>Standard Correlation Coefficient : 표준 상관 계수</p></li>
<li><p>Standard Deviation : 표준 편차</p></li>
<li><p>Statistics : 통계량</p></li>
<li><p>Static model : 정적 모델</p></li>
<li><p>Stationarity : 정상성</p></li>
<li><p>Stationary Distribution : 정상분포</p></li>
<li><p>Step : 단계</p></li>
<li><p>Step Function : 계단 함수</p></li>
<li><p>Step size : 단계 크기</p></li>
<li><p>Stochastic gradient descent : 확률적 경사 하강법</p></li>
<li><p>Stop Words : 불용어 처리</p></li>
<li><p>Stratified sampling : 계층적 샘플링</p></li>
<li><p>Stride : 스트라이드 (커널 이동 보폭)</p></li>
<li><p>Structural risk minimization : 구조적 위험 최소화</p></li>
<li><p>Subsampling : 서브샘플링</p></li>
<li><p>Subspace : 부분차원</p></li>
<li><p>Summary : 요약</p></li>
<li><p>Supervised Learning : 지도학습</p></li>
<li><p>Supervised machine learning : 지도 기계 학습</p></li>
<li><p>Support Vector Machine(SVM) : 서포트 벡터 머신</p></li>
<li><p>Synthetic feature : 합성 특성</p></li>
<li><p>Target : 목표</p></li>
<li><p>Temporal data : 시계열 데이터</p></li>
<li><p>Temporal Difference : 시간차</p></li>
<li><p>Tensor : 텐서</p></li>
<li><p>Tensor rank : 텐서 랭크</p></li>
<li><p>Tensor shape : 텐서 형태</p></li>
<li><p>Tensor size : 텐서 크기</p></li>
<li><p>TensorBoard : 텐서보드</p></li>
<li><p>TensorFlow : 텐서플로우</p></li>
<li><p>TensorFlow Playground : 텐서플로우 플레이그라운드</p></li>
<li><p>TensorFlow Serving : 텐서플로우 서빙</p></li>
<li><p>Term Frequency : 단어 빈도</p></li>
<li><p>Test error : 테스트 오차</p></li>
<li><p>Test Set : 시험셋</p></li>
<li><p>Time series analysis : 시계열 분석</p></li>
<li><p>Time-series data : 시계열 데이터</p></li>
<li><p>Time-series forecasting : 시계열 예측</p></li>
<li><p>Token : 토큰</p></li>
<li><p>Tokenization : 토큰화</p></li>
<li><p>Tolerance : 허용 오차</p></li>
<li><p>Topic : 토픽</p></li>
<li><p>Topic Model : 토픽모델</p></li>
<li><p>Training : 학습</p></li>
<li><p>Training Data : 학습 데이터</p></li>
<li><p>Training error : 학습 오차</p></li>
<li><p>Training Instance : 학습 사례</p></li>
<li><p>Training Set : 학습셋</p></li>
<li><p>Train-Test data split : 학습-평가 데이터 나누기</p></li>
<li><p>Transfer Learning : 전이 학습</p></li>
<li><p>Translation invariance : 이동 불변성</p></li>
<li><p>Trial : 시행</p></li>
<li><p>True Negative : 참 음성</p></li>
<li><p>True Positive : 참 양성</p></li>
<li><p>True positive rate : 참 양성률</p></li>
<li><p>Underfitting : 과소적합</p></li>
<li><p>Univariate regression : 단변량 회귀</p></li>
<li><p>Unlabeled example : 레이블되지 않은 보기</p></li>
<li><p>Unsupervised Learning : 비지도 학습</p></li>
<li><p>Unsupervised machine learning : 비지도 기계 학습</p></li>
<li><p>Unsupervised pre-learning : 비지도 선행 학습</p></li>
<li><p>UV decomposition : UV 분해</p></li>
<li><p>Validation : 검증</p></li>
<li><p>Validation Set : 검증셋</p></li>
<li><p>Vanishing gradient : 기울기 소실</p></li>
<li><p>Variable : 변량, 변수</p></li>
<li><p>Variance : 분산</p></li>
<li><p>Vectorization : 벡터화</p></li>
<li><p>Visible layer : 가시 레이어</p></li>
<li><p>Visualization : 시각화</p></li>
<li><p>Vocabulary : 어휘</p></li>
<li><p>Weight : 가중치</p></li>
<li><p>Weight Decay : 가중치 감소</p></li>
<li><p>Weighted Graph : 가중 그래프</p></li>
<li><p>Whiting : 백색화</p></li>
<li><p>Wide model : 와이드 모델</p></li>
<li><p>Word Embedding : 워드 임베딩</p></li>
<li><p>Zero padding : 제로페딩</p></li>
<li><p>Zero-shot learning : 제로샷 학습</p></li>
<li><p>Z-score standardization : z-점수 표준화</p></li>
</ul>

		</div>
		<footer class="post__footer">
			
<div class="post__tags tags clearfix">
	<svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5 0 11V3C0 1.5.8.8.8.8S1.5 0 3 0h8c1.5 0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg>
	<ul class="tags__list">
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/machine-learning/" rel="tag">Machine Learning</a>
		</li>
		<li class="tags__item">
			<a class="tags__link btn" href="/tags/%EC%9A%A9%EC%96%B4%EC%82%AC%EC%A0%84/" rel="tag">용어사전</a>
		</li>
	</ul>
</div>
		</footer>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/post/2021-08-22-rstudio-addin/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RStudio Addin을 만드는 방법</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/post/2022-02-23-r-markdown/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">R Markdown 문서 편집</p>
		</a>
	</div>
</nav>


			</div>
			<aside class="sidebar"><div class="widget-search widget">
	<form class="widget-search__form" role="search" method="get" action="https://google.com/search">
		<label>
			<input class="widget-search__field" type="search" placeholder="SEARCH…" value="" name="q" aria-label="SEARCH…">
		</label>
		<input class="widget-search__submit" type="submit" value="Search">
		<input type="hidden" name="sitesearch" value="https://manboha.github.io/" />
	</form>
</div>
<div class="widget-recent widget">
	<h4 class="widget__title">Recent Posts</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item"><a class="widget__link" href="/post/2022-06-25-r-start/">R 처음 시작하기</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2022-06-24-r-rstudio-install/">R 및 RStudio 설치</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2022-06-23-create-new-variables-from-existing-variables/">기존 변수에서 새 변수 만들기</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2022-02-23-r-markdown/">R Markdown 문서 편집</a></li>
			<li class="widget__item"><a class="widget__link" href="/post/2021-09-20-machine-learning-dictionary/">Machine Learning 영한 사전</a></li>
		</ul>
	</div>
</div>
<div class="widget-categories widget">
	<h4 class="widget__title">Categories</h4>
	<div class="widget__content">
		<ul class="widget__list">
			<li class="widget__item">
				<a class="widget__link" href="/categories/machine-learning/">Machine Learning</a></li>
			<li class="widget__item">
				<a class="widget__link" href="/categories/r/">R</a></li>
		</ul>
	</div>
</div>
<div class="widget-taglist widget">
	<h4 class="widget__title">Tags</h4>
	<div class="widget__content">
		<a class="widget-taglist__link widget__link btn" href="/tags/addin/" title="Addin">Addin</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/case_when/" title="case_when">case_when</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/cctv/" title="cctv">cctv</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/crimes-in-seoul/" title="Crimes in Seoul">Crimes in Seoul</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/decision-tree/" title="decision tree">decision tree</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/dplyr/" title="dplyr">dplyr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/eda/" title="EDA">EDA</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/excel/" title="excel">excel</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/install/" title="install">install</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/machine-learning/" title="Machine Learning">Machine Learning</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/markdown/" title="Markdown">Markdown</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/mutate/" title="mutate">mutate</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/purrr/" title="purrr">purrr</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/rmarkdown/" title="Rmarkdown">Rmarkdown</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/rstudio/" title="RStudio">RStudio</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/seoul/" title="seoul">seoul</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/tidyverse/" title="tidyverse">tidyverse</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EA%B8%B0%EC%B4%88/" title="기초">기초</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EB%8B%A4%EC%B0%A8%EC%9B%90-%EB%8D%B0%EC%9D%B4%ED%84%B0/" title="다차원 데이터">다차원 데이터</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EB%B2%94%EC%A3%84/" title="범죄">범죄</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EB%B3%80%EC%88%98/" title="변수">변수</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EC%84%9C%EC%9A%B8%EC%8B%9C/" title="서울시">서울시</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EC%8B%9C%EA%B0%81%ED%99%94/" title="시각화">시각화</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EC%9A%A9%EC%96%B4%EC%82%AC%EC%A0%84/" title="용어사전">용어사전</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%EC%9D%98%EC%82%AC%EA%B2%B0%EC%A0%95%EB%82%98%EB%AC%B4/" title="의사결정나무">의사결정나무</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%ED%8C%A8%ED%82%A4%EC%A7%80/" title="패키지">패키지</a>
		<a class="widget-taglist__link widget__link btn" href="/tags/%ED%95%A8%EC%88%98/" title="함수">함수</a>
	</div>
</div>
</aside>
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2022 Bohak Maeng.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
	</div>
<script async defer src="/js/menu.js"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script>
</body>
</html>